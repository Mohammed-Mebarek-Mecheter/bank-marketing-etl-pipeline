# Bank Marketing ETL Pipeline

## Overview

Personal loans are a lucrative revenue stream for banks. The typical interest rate of a two-year loan in the United Kingdom is [around 10%](https://www.experian.com/blogs/ask-experian/whats-a-good-interest-rate-for-a-personal-loan/). This might not sound like a lot, but in September 2022 alone UK consumers borrowed [around £1.5 billion](https://www.ukfinance.org.uk/system/files/2022-12/Household%20Finance%20Review%202022%20Q3-%20Final.pdf), which would mean approximately £300 million in interest generated by banks over two years!

We have been asked to work with a bank to clean the data they collected as part of a recent marketing campaign, which aimed to get customers to take out a personal loan. They plan to conduct more marketing campaigns going forward so would like you to ensure it conforms to the specific structure and data types that they specify so that they can then use the cleaned data you provide to set up a PostgreSQL database, which will store this campaign's data and allow data from future campaigns to be easily imported.

They have supplied us with a csv file called `"bank_marketing.csv"`, which we will need to clean, reformat, and split the data, saving three final csv files. Specifically, the three files should have the names and contents as outlined below:

## `client.csv`

| column | data type | description | cleaning requirements |
|--------|-----------|-------------|-----------------------|
| `client_id` | `integer` | Client ID | N/A |
| `age` | `integer` | Client's age in years | N/A |
| `job` | `object` | Client's type of job | Change `"."` to `"_"` |
| `marital` | `object` | Client's marital status | N/A |
| `education` | `object` | Client's level of education | Change `"."` to `"_"` and `"unknown"` to `np.NaN` |
| `credit_default` | `bool` | Whether the client's credit is in default | Convert to `boolean` data type:<br> `1` if `"yes"`, otherwise `0` |
| `mortgage` | `bool` | Whether the client has an existing mortgage (housing loan) | Convert to boolean data type:<br> `1` if `"yes"`, otherwise `0` |

<br>

## `campaign.csv`

| column | data type | description | cleaning requirements |
|--------|-----------|-------------|-----------------------|
| `client_id` | `integer` | Client ID | N/A |
| `number_contacts` | `integer` | Number of contact attempts to the client in the current campaign | N/A |
| `contact_duration` | `integer` | Last contact duration in seconds | N/A |
| `previous_campaign_contacts` | `integer` | Number of contact attempts to the client in the previous campaign | N/A |
| `previous_outcome` | `bool` | Outcome of the previous campaign | Convert to boolean data type:<br> `1` if `"success"`, otherwise `0`. |
| `campaign_outcome` | `bool` | Outcome of the current campaign | Convert to boolean data type:<br> `1` if `"yes"`, otherwise `0`. |
| `last_contact_date` | `datetime` | Last date the client was contacted | Create from a combination of `day`, `month`, and a newly created `year` column (which should have a value of `2022`); <br> **Format =** `"YYYY-MM-DD"` |

<br>

## `economics.csv`

| column | data type | description | cleaning requirements |
|--------|-----------|-------------|-----------------------|
| `client_id` | `integer` | Client ID | N/A |
| `cons_price_idx` | `float` | Consumer price index (monthly indicator) | N/A |
| `euribor_three_months` | `float` | Euro Interbank Offered Rate (euribor) three-month rate (daily indicator) | N/A |

## Project Structure

The project directory follows a structured layout, facilitating easy navigation and maintenance:

```
project/
├── data/
│   ├── bank_marketing.csv
│   ├── client.csv
│   ├── campaign.csv
│   └── economics.csv
├── etl/
│   ├── __init__.py
│   ├── extract.py
│   ├── transform.py
│   └── load.py
├── output/
├── pipeline/
│   └── bonobo_pipeline.py
│   ├── mETL_pipeline.py
│   ├── luigi_pipeline.py
├── workflow/
│   └── prefect_pipeline.py
├── config.yaml
├── config.ini
├── main.py
└── README.md
```

## Prerequisites

Before running the ETL pipeline, ensure that the following prerequisites are met:

- Python 3.x
- PostgreSQL database
  ![The Database](Schema.PNG)
- pip install -r requirements.txt

## Configuration

1. Update the `config.ini` file with your PostgreSQL connection details.
2. Modify the `config.yaml` file to define table names, SQL queries, and file paths as per your project requirements.

## Running the Luigi Pipeline

Execute the Luigi pipeline by following these steps:

1. Navigate to the project directory:

   ```bash
   cd project
   ```

2. Run the Bonobo pipeline:

   ```bash
   python pipeline/luigi_pipeline.py
   ```

## Running the Prefect Workflow

Apply the Prefect deployment to run the ETL workflow automatically:

1. Navigate to the project directory:

   ```bash
   cd project
   ```

2. Deploy the Prefect workflow:

   ```bash
   python main.py
   ```

## ETL Process

The ETL process comprises three main steps:

1. **Extract**: The `extract.py` module reads data from CSV files (`client.csv`, `campaign.csv`, and `economics.csv`) and stores it in separate DataFrames.

2. **Transform**: The `transform.py` module cleans and transforms the raw data, handling duplicates, missing values, and data type conversions, as required.

3. **Load**: The `load.py` module establishes a connection to the PostgreSQL database, creates necessary tables based on the schema defined in `config.yaml`, and inserts cleaned data into respective tables.

## Customization

Customize the ETL process by modifying the modules (`extract.py`, `transform.py`, and `load.py`) to suit specific project requirements. Additionally, update configurations in `config.yaml` and `config.ini` as needed.

## Contributions

Contributions to this project are welcomed. To report issues or suggest improvements, please open an issue or submit a pull request.

